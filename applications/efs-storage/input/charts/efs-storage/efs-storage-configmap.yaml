apiVersion: v1
data:
  efs-storage.sh: |-
    #!/bin/bash
    set -o pipefail

    readonly RED='\033[0;31m'
    readonly GREEN='\033[0;32m'
    readonly ORANGE='\033[38;5;214m'
    readonly NC='\033[0m' # No Color
    readonly RUN_DIR=$(pwd)

    echo "ðŸŒ´ Create EFS storage..."

    # script works for sno or for all instances
    IS_SNO=${IS_SNO:-}

    if [ -z "$AWS_PROFILE" ] && [ -z "$AWS_DEFAULT_REGION" ]; then
        export AWS_DEFAULT_REGION=$(oc -n openshift-machine-api get $(oc get machines.machine.openshift.io -o name -A) -o json | jq -r '.spec.providerSpec.value.placement.region')
        if [ -z "$AWS_DEFAULT_REGION" ]; then
            echo -e "ðŸš¨${RED}Failed - to find AWS_DEFAULT_REGION ? ${NC}"
            exit 1
        fi
    fi

    # Check for EnvVars
    [ ! -z "$AWS_PROFILE" ] && echo "ðŸŒ´ Using AWS_PROFILE: $AWS_PROFILE"
    [ -z "$AWS_PROFILE" ] && [ -z "$AWS_ACCESS_KEY_ID" ] && echo "ðŸ•± Error: AWS_ACCESS_KEY_ID not set in env" && exit 1
    [ -z "$AWS_PROFILE" ] && [ -z "$AWS_SECRET_ACCESS_KEY" ] && echo "ðŸ•± Error: AWS_SECRET_ACCESS_KEY not set in env" && exit 1
    [ -z "$AWS_PROFILE" ] && [ -z "$AWS_DEFAULT_REGION" ] && echo "ðŸ•± Error: AWS_DEFAULT_REGION not set in env" && exit

    # create efs per vpc
    create_efs() {
        local instanceId="$1"
        EFSID=
        TAGS_SPEC=

        echo "ðŸŒ´ create_efs - Processing: $instanceId"

        IFS=$'\n' read -d '' -r -a lines < <(aws ec2 describe-tags --filters "Name=resource-id,Values=${instanceId}" --output text)
        TAGS+=Key=Name,Value=ocp-efs-${instanceId}
        TAGS+=" "
        if [ ! -z "$lines" ]; then
            set -o pipefail
            for line in "${lines[@]}"; do
                read -r type key resourceid resourcetype value <<< "$line"
                # troublesome, quoting, adding tags for deletion
                if [ "$key" != "Name" ] && [ "$key" != "description" ] && [ "$key" != "owner" ] ; then
                    TAGS+=Key=$key,Value=$value
                    TAGS+=" "
                    TAGS_SPEC+={Key="$key",Value="$value"},
                fi
            done
        else 
            echo -e "ðŸ’€${ORANGE} No tags found for instance ${instanceId} ? ${NC}";
        fi

        if [ $(aws efs describe-file-systems --query "FileSystems[].FileSystemId" --output text | wc -l) -eq 0 ]; then
            echo "ðŸŒ´ No EFS file systems found - Creating."

            fsid=$(aws efs create-file-system --region=${AWS_DEFAULT_REGION} --performance-mode=generalPurpose --encrypted --tags ${TAGS%?} | jq --raw-output '.FileSystemId')
            if [ -z "$fsid" ]; then
                echo -e "ðŸš¨${RED}Failed - to create efs filesystem ocp-efs ? ${NC}"
                exit 1
            fi
            export EFSID=${fsid}

            vpcid=$(aws ec2 describe-instances --instance-ids ${instanceId} --query 'Reservations[0].Instances[0].VpcId' --output text)
            if [ -z "$vpcid" ]; then
                echo -e "ðŸš¨${RED}Failed - to find vpcid for ${instanceId} ? ${NC}"
                exit 1
            fi

            create_mount_target ${vpcid} ${EFSID} ${TAGS_SPEC}

        else
            # we have to iterate over them
            echo "ðŸŒ´ Found EFS file system - checking."
            found=
            for fsid in $(aws efs describe-file-systems --query 'FileSystems[*].FileSystemId' --output text); do
                if [ $(aws efs describe-tags --file-system-id $fsid | grep ${instanceId} | wc -l) -gt 0 ]; then
                    echo "Filesystem $fsid exists for $instanceId, skipping ..."
                    found="true"
                    export EFSID=${fsid}
                fi
            done
            if [ -z ${found} ]; then
                echo "ðŸŒ´ No EFS file systems found - Creating."
                fsid=$(aws efs create-file-system --region=${AWS_DEFAULT_REGION} --performance-mode=generalPurpose --encrypted --tags ${TAGS%?} | jq --raw-output '.FileSystemId')
                if [ -z "$fsid" ]; then
                    echo -e "ðŸš¨${RED}Failed - to create efs filesystem ocp-efs ? ${NC}"
                    exit 1
                fi
                export EFSID=${fsid}

                vpcid=$(aws ec2 describe-instances --instance-ids ${instanceId} --query 'Reservations[0].Instances[0].VpcId' --output text)
                if [ -z "$vpcid" ]; then
                    echo -e "ðŸš¨${RED}Failed - to find vpcid for ${instanceId} ? ${NC}"
                    exit 1
                fi

                create_mount_target ${vpcid} ${EFSID} ${TAGS_SPEC}
            fi
        fi
    }

    create_mount_target() {
        local vpcid="$1"
        local efsid="$2"
        local tagsspec="$3"

        echo "ðŸŒ´ create_mount_target - Processing: $vpcid $efsid $tagsspec"

        vpcname=$(aws ec2 describe-vpcs --vpc-ids ${vpcid} --query "Vpcs[].Tags[?Key=='Name'].Value" --output text)
        if [ -z "$vpcname" ]; then
            echo -e "ðŸš¨${RED}Failed - failed to find vpcname for vpcid: ${vpcid} region: ${AWS_DEFAULT_REGION} ? ${NC}"
            exit 1
        fi

        cidr_block=$(aws ec2 describe-vpcs --region=${AWS_DEFAULT_REGION} --vpc-ids ${vpcid} --query "Vpcs[].CidrBlock" --output text)
        if [ -z "$cidr_block" ]; then
            echo -e "ðŸš¨${RED}Failed - failed to find CIDR for vpcid: ${vpcid} region: ${AWS_DEFAULT_REGION} ? ${NC}"
            exit 1
        fi

        mount_target_group_name="ec2-efs-group"
        mount_target_group_desc="NFS access to EFS from EC2 worker nodes"
        mount_target_group_id=$(aws ec2 create-security-group --region=${AWS_DEFAULT_REGION} --group-name $mount_target_group_name --description "${mount_target_group_desc}" --tag-specifications "ResourceType=security-group,Tags=[${tagsspec%?}]" --vpc-id ${vpcid} | jq --raw-output '.GroupId')
        if [ -z "$mount_target_group_id" ]; then
            echo -e "ðŸš¨${RED}Failed - failed to create SG for mount target group: ${mount_target_group_name} in region: ${AWS_DEFAULT_REGION} ? ${NC}"
            exit 1
        fi

        aws ec2 authorize-security-group-ingress --region=${AWS_DEFAULT_REGION} --group-id ${mount_target_group_id} --protocol tcp --port 2049 --cidr ${cidr_block} | jq .
        if [ "${PIPESTATUS[0]}" != 0 ]; then
            echo -e "ðŸš¨${RED}Failed - to authorize security group ingress for group-id: ${mount_target_group_id} in region: ${AWS_DEFAULT_REGION}?${NC}"
            exit 1
        fi

        # us-east-2, ap-southeast-2
        TAG1=${vpcname%%-vpc}-subnet-public-${AWS_DEFAULT_REGION}a
        TAG2=${vpcname%%-vpc}-subnet-public-${AWS_DEFAULT_REGION}b
        TAG3=${vpcname%%-vpc}-subnet-public-${AWS_DEFAULT_REGION}c
        subnets=$(aws ec2 describe-subnets --region=${AWS_DEFAULT_REGION} --filters "Name=tag:Name,Values=$TAG1,$TAG2,$TAG3" | jq --raw-output '.Subnets[].SubnetId')
        for subnet in ${subnets};
        do
        echo "creating mount target in " $subnet
        aws efs create-mount-target --region=${AWS_DEFAULT_REGION} --file-system-id ${efsid} --subnet-id ${subnet} --security-groups ${mount_target_group_id}
        if [ "$?" != 0 ]; then
            echo -e "ðŸ’€${ORANGE} Failed to create mount target for fsid: ${efsid} and subnet: ${subnet} with sg: ${mount_target_group_id} in region: ${AWS_DEFAULT_REGION} ? ${NC}";
        fi
        done
        if [ -z "$subnets" ]; then
            echo -e "ðŸ’€${ORANGE} Could not find subnets for vpc ${vpcname}, mount targets not created - check TAG names $TAG1,$TAG2,$TAG3 ? ${NC}";
        fi
    }

    configure_sc() {
        if [ -z $IS_SNO ]; then
          echo "ðŸŒ´ IS_SNO not true, skipping configure_sc..."
          return
        fi

        oc get sc/efs-sc
        if [ "$?" == 0 ]; then
            echo "ðŸŒ´ Found EFS storage class OK - Done."
            exit 0
        fi

        echo "ðŸŒ´ Running configure_sc..."

    cat << EOF > /tmp/storage-class-efs.yaml
    kind: StorageClass
    apiVersion: storage.k8s.io/v1
    metadata:
      name: efs-sc
    provisioner: efs.csi.aws.com
    parameters:
      provisioningMode: efs-ap 
      fileSystemId: $EFSID
      directoryPerms: "700" 
      gidRangeStart: "1000" 
      gidRangeEnd: "2000" 
      basePath: "/dynamic_provisioning" 
    EOF

        oc apply -f /tmp/storage-class-efs.yaml -n openshift-config
        if [ "$?" != 0 ]; then
          echo -e "ðŸš¨${RED}Failed - to create storage class, configure_sc ?${NC}"
          exit 1
        fi
        rm -f /tmp/storage-class-efs.yaml 2>&1>/dev/null
        echo "ðŸŒ´ configure_sc ran OK"
    }

    INSTANCE_IDS=

    # get single sno
    if [ ! -z $IS_SNO ]; then
        export INSTANCE_IDS=$(oc -n openshift-machine-api get $(oc get machines.machine.openshift.io -o name -A) -o json | jq -r '.status.providerStatus.instanceId')
    else
        # get all instances
        export INSTANCE_IDS=$(aws ec2 describe-instances \
            --query "Reservations[].Instances[].InstanceId" \
            --filters "Name=tag-value,Values=*-master-0" \
            --output text)
    fi

    # check if EFS exists for each SNO instance else create
    for cluster in ${INSTANCE_IDS}; do
        create_efs $cluster
        configure_sc
    done

    echo "ðŸŒ´ Create EFS storage Done."
    exit 0
kind: ConfigMap
metadata:
  name: efs-storage
  namespace: openshift-config
