apiVersion: v1
data:
  check-install.sh: |-
    #!/bin/bash
    set -o pipefail

    readonly RED='\033[0;31m'
    readonly GREEN='\033[0;32m'
    readonly ORANGE='\033[38;5;214m'
    readonly NC='\033[0m' # No Color

    wait_for_openshift_api() {
        local i=0
        HOST=https://api.${BASE_DOMAIN}:6443/healthz
        until [ $(curl --connect-timeout 3 -k -s -o /dev/null -w %{http_code} ${HOST}) = "200" ]
        do
            echo -e "${GREEN}Waiting for 200 response from openshift api ${HOST}.${NC}"
            sleep 5
            ((i=i+1))
            if [ $i -gt 100 ]; then
                echo -e "ðŸ•±${RED}Failed - OpenShift api ${HOST} never ready?.${NC}"
                exit 1
            fi
        done
        echo "ðŸŒ´ wait_for_openshift_api ran OK"
    }

    wait_cluster_settle() {
        echo "ðŸŒ´ Running wait_cluster_settle..."
        oc adm wait-for-stable-cluster --minimum-stable-period=300s --timeout=20m
        echo "ðŸŒ´ wait_cluster_settle ran OK"
    }

    force_argocd_sync() {
        echo "ðŸŒ´ Running force_argocd_sync..."

        # these apps need vault secrets
        for x in policy-collection-sno llama-stack-playground-local-cluster; do
        oc -n openshift-gitops patch applications.argoproj.io $x --type=merge --patch '
    operation:
      initiatedBy:
        username: admin
      sync:
        syncStrategy:
          hook: {}
    '
        done
        for x in policy-collection-sno llama-stack-playground-local-cluster; do
            oc -n openshift-gitops annotate applications.argoproj.io/$x argocd.argoproj.io/refresh="hard"
        done
        echo "ðŸŒ´ force_argocd_sync ran OK"
    }

    check_pods_allocatable() {
        echo "ðŸŒ´ Running check_pods_allocatable..."
        local i=0
        PODS=$(oc get $(oc get node -o name -l node-role.kubernetes.io/master="") -o=jsonpath={.status.allocatable.pods})
        until [ "$PODS" == 500 ]
        do
            echo -e "${GREEN}Waiting for pods $PODS to equal 500.${NC}"
            ((i=i+1))
            if [ $i -gt 300 ]; then
                echo -e "ðŸ•±${RED}Failed - node allocatable pods wrong - $PODS?.${NC}"
                exit 1
            fi
            if [ $i > 100 ]; then
                echo -e "ðŸ’€${ORANGE}Warn - check_pods_allocatable, forcing kubeletconfigs, continuing ${NC}"
                # MC bug, does not always trigger it seems - argocd will recreate this
                if oc get kubeletconfig set-image-gc -o yaml | grep "could not"; then
                    oc delete kubeletconfig set-image-gc
                fi
                if oc get kubeletconfig set-max-pods -o yaml | grep "could not"; then
                    oc delete kubeletconfig set-max-pods
                fi
            fi
            sleep 10
            PODS=$(oc get $(oc get node -o name -l node-role.kubernetes.io/master="") -o=jsonpath={.status.allocatable.pods})
        done
        echo "ðŸŒ´ check_pods_allocatable $PODS ran OK"
    }

    check_gpus_allocatable() {
        echo "ðŸŒ´ Running check_gpus_allocatable..."
        local i=0
        GPUS=$(oc get $(oc get node -o name -l node-role.kubernetes.io/master="") -o=jsonpath={.status.allocatable.nvidia\\.com\\/gpu})
        until [ "$GPUS" == 8 ]
        do
            echo -e "${GREEN}Waiting for gpus $GPUS to equal 8.${NC}"
            ((i=i+1))
            if [ $i -gt 200 ]; then
                echo -e "ðŸ•±${RED}Failed - node allocatable gpus wrong - $GPUS?.${NC}"
                exit 1
            fi
            sleep 10
            # buggy 4.19 - sometimes the image-prune job holds up cluster install completion which holds up gpu operator
            STATUS=$(oc -n openshift-image-registry get jobs 2>&1 | grep Failed | wc -l)
            if [ "$STATUS" -gt 0 ]; then
                oc -n openshift-image-registry delete cronjob image-pruner
            fi
            # buggy 4.19 - get scc error for nfd - Error creating: pods "nfd-worker-" is forbidden:
            NFD_STATUS=$(oc -n openshift-nfd describe ds nfd-worker | grep "Created pod: nfd-worker" | wc -l)
            if [ "${NFD_STATUS}" -eq 0 ] && [ "$i" > 50 ]; then
                oc delete pod --all -n openshift-nfd
                sleep 15
            fi
            GPUS=$(oc get $(oc get node -o name -l node-role.kubernetes.io/master="") -o=jsonpath={.status.allocatable.nvidia\\.com\\/gpu})
        done
        echo "ðŸŒ´ check_gpus_allocatable $GPUS ran OK"
    }

    check_istio_pods() {
        echo "ðŸŒ´ Running check_istio_pods..."
        local i=0
        PODS=$(oc get pods -n openshift-ingress -l app.kubernetes.io/instance=openshift-gateway-istiod --no-headers=true | wc -l)
        until [ "$PODS" > 0 ]
        do
            echo -e "${GREEN}Waiting for istio-system $PODS.${NC}"
            ((i=i+1))
            if [ $i -gt 200 ]; then
                echo -e "ðŸ•±${RED}Failed - istio-system pods never ready - $PODS?.${NC}"
                exit 1
            fi
            sleep 10
            PODS=$(oc get pods -n openshift-ingress -l app.kubernetes.io/instance=openshift-gateway-istiod --no-headers=true | wc -l)
        done
        echo "ðŸŒ´ check_istio_pods $PODS ran OK"
    }

    check_resource_flavor() {
        echo "ðŸŒ´ Running check_resource_flavor..."
        local i=0
        RF=$(oc get ResourceFlavor.kueue.x-k8s.io nvidia-gpu-flavor --no-headers=true | wc -l)
        until [ "$RF" > 0 ]
        do
            echo -e "${GREEN}Waiting for nvidia-gpu-flavor $RF.${NC}"
            ((i=i+1))
            if [ $i -gt 200 ]; then
                echo -e "ðŸ•±${RED}Failed - nvidia-gpu-flavor never ready - $RF?.${NC}"
                exit 1
            fi
            sleep 10
            # buggy 3.0 - ordering with cluster queue and gpu operator
            if [ "$RF" -eq 0 ] && [ "$i" > 50 ]; then
                oc delete ClusterQueue default 
                sleep 15
            fi
            RF=$(oc get ResourceFlavor.kueue.x-k8s.io nvidia-gpu-flavor --no-headers=true | wc -l)
        done
        echo "ðŸŒ´ check_resource_flavor $RF ran OK"
    }

    check_llm_pods() {
        echo "ðŸŒ´ Running check_llm_pods..."
        local i=0
        PODS=$(oc get pods -n llama-serving | grep -e Running | grep -e 2/2 | wc -l)
        until [ "$PODS" == 2 ]
        do
            echo -e "${GREEN}Waiting for llm pods $PODS to equal 2.${NC}"
            ((i=i+1))
            if [ $i -gt 200 ]; then
                echo -e "ðŸ•±${RED}Failed - llm pods wrong - $PODS?.${NC}"
                exit 1
            fi
            sleep 10
            # this is because we need llama to start first before deepseek
            # vllm gpu_memory_utilization is calc on "current available" not actual
            # and we cannot predict who will start up first
            if [ "$PODS" -eq 0 ]; then
                # undeploy deepseek
                oc -n llama-serving annotate --overwrite inferenceservice sno-deepseek-qwen3-vllm serving.kserve.io/stop="true"
            fi
            LLAMA_STATUS=$(oc -n llama-serving get $(oc get pods -n llama-serving -l app=isvc.llama3-2-3b-predictor -o name) -o=jsonpath='{.status.conditions[?(@.type=="Ready")].status}')
            if [ "$LLAMA_STATUS" == "True" ] && [ "$i" > 50 ]; then
                # redeploy deepseek-qwen3
                oc -n llama-serving annotate --overwrite inferenceservice sno-deepseek-qwen3-vllm serving.kserve.io/stop="false"
            fi
            PODS=$(oc get pods -n llama-serving | grep -e Running | grep -e 2/2 | wc -l)
        done
        echo "ðŸŒ´ check_llm_pods $PODS ran OK"
    }

    check_llama_stack() {
        echo "ðŸŒ´ Running check_llama_stack..."
        PODS=$(oc -n llama-stack get pod -l app.kubernetes.io/instance=llamastack-with-config | grep Running)
        if [ -z $PODS ]; then
            oc -n llama-stack delete $(oc -n llama-stack get pod -l app.kubernetes.io/instance=llamastack-with-config -o name)
        fi
    }

    export BASE_DOMAIN=$(oc get dns cluster -o jsonpath='{.spec.baseDomain}')
    [ -z "$BASE_DOMAIN" ] && echo "ðŸ•± Error: must supply BASE_DOMAIN in env" && exit 1
    echo "ðŸŒ´ BASE_DOMAIN set to $BASE_DOMAIN"

    wait_for_openshift_api
    wait_cluster_settle
    force_argocd_sync
    check_pods_allocatable
    check_gpus_allocatable
    check_istio_pods
    check_resource_flavor
    check_llm_pods
    check_llama_stack

    echo -e "\nðŸŒ»${GREEN}Check Install ended OK.${NC}ðŸŒ»\n"
    exit 0
kind: ConfigMap
metadata:
  name: check-install
  namespace: openshift-config
